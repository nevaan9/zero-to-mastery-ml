{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6168ba81",
   "metadata": {},
   "source": [
    "# Predicting Heart Disease\n",
    "#### Follows: end-to-end-heart-disease-classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3d37c",
   "metadata": {},
   "source": [
    "## 1. Problem Definition\n",
    "In our case, the problem we will be exploring is **binary classification** (a sample can only be one of two things). \n",
    "\n",
    "This is because we're going to be using a number of differnet **features** (pieces of information) about a person to predict whether they have heart disease or not.\n",
    "\n",
    "In a statement,\n",
    "\n",
    "> Given clinical parameters about a patient, can we predict whether or not they have heart disease?\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "What you'll want to do here is dive into the data your problem definition is based on. This may involve, sourcing, defining different parameters, talking to experts about it and finding out what you should expect.\n",
    "\n",
    "The original data came from the [Cleveland database](https://archive.ics.uci.edu/ml/datasets/heart+Disease) from UCI Machine Learning Repository.\n",
    "\n",
    "Howevever, we've downloaded it in a formatted way from [Kaggle](https://www.kaggle.com/ronitf/heart-disease-uci/).\n",
    "\n",
    "The original database contains 76 attributes, but here only 14 attributes will be used. **Attributes** (also called **features**) are the variables what we'll use to predict our **target variable**.\n",
    "\n",
    "Attributes and features are also referred to as **independent variables** and a target variable can be referred to as a **dependent variable**.\n",
    "\n",
    "> We use the independent variables to predict our dependent variable.\n",
    "\n",
    "Or in our case, the independent variables are a patients different medical attributes and the dependent variable is whether or not they have heart disease.\n",
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "The evaluation metric is something you might define at the start of a project.\n",
    "\n",
    "Since machine learning is very experimental, you might say something like, \n",
    "\n",
    "> If we can reach 95% accuracy at predicting whether or not a patient has heart disease during the proof of concept, we'll pursure this project.\n",
    "\n",
    "The reason this is helpful is it provides a rough goal for a machine learning engineer or data scientist to work towards.\n",
    "\n",
    "However, due to the nature of experimentation, the evaluation metric may change over time.\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "Features are different parts of the data. During this step, you'll want to start finding out what you can about the data.\n",
    "\n",
    "One of the most common ways to do this, is to create a **data dictionary**.\n",
    "\n",
    "### Heart Disease Data Dictionary\n",
    "\n",
    "A data dictionary describes the data you're dealing with. Not all datasets come with them so this is where you may have to do your research or ask a **subject matter expert** (someone who knows about the data) for more.\n",
    "\n",
    "The following are the features we'll use to predict our target variable (heart disease or no heart disease).\n",
    "\n",
    "1. age - age in years \n",
    "2. sex - (1 = male; 0 = female) \n",
    "3. cp - chest pain type \n",
    "    * 0: Typical angina: chest pain related decrease blood supply to the heart\n",
    "    * 1: Atypical angina: chest pain not related to heart\n",
    "    * 2: Non-anginal pain: typically esophageal spasms (non heart related)\n",
    "    * 3: Asymptomatic: chest pain not showing signs of disease\n",
    "4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n",
    "    * anything above 130-140 is typically cause for concern\n",
    "5. chol - serum cholestoral in mg/dl \n",
    "    * serum = LDL + HDL + .2 * triglycerides\n",
    "    * above 200 is cause for concern\n",
    "6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n",
    "    * '>126' mg/dL signals diabetes\n",
    "7. restecg - resting electrocardiographic results\n",
    "    * 0: Nothing to note\n",
    "    * 1: ST-T Wave abnormality\n",
    "        - can range from mild symptoms to severe problems\n",
    "        - signals non-normal heart beat\n",
    "    * 2: Possible or definite left ventricular hypertrophy\n",
    "        - Enlarged heart's main pumping chamber\n",
    "8. thalach - maximum heart rate achieved \n",
    "9. exang - exercise induced angina (1 = yes; 0 = no) \n",
    "10. oldpeak - ST depression induced by exercise relative to rest \n",
    "    * looks at stress of heart during excercise\n",
    "    * unhealthy heart will stress more\n",
    "11. slope - the slope of the peak exercise ST segment\n",
    "    * 0: Upsloping: better heart rate with excercise (uncommon)\n",
    "    * 1: Flatsloping: minimal change (typical healthy heart)\n",
    "    * 2: Downslopins: signs of unhealthy heart\n",
    "12. ca - number of major vessels (0-3) colored by flourosopy \n",
    "    * colored vessel means the doctor can see the blood passing through\n",
    "    * the more blood movement the better (no clots)\n",
    "13. thal - thalium stress result\n",
    "    * 1,3: normal\n",
    "    * 6: fixed defect: used to be defect but ok now\n",
    "    * 7: reversable defect: no proper blood movement when excercising \n",
    "14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)\n",
    "\n",
    "**Note:** No personal identifiable information (PPI) can be found in the dataset.\n",
    "\n",
    "It's a good idea to save these to a Python dictionary or in an external file, so we can look at them later without coming back here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9940032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prapare our tools\n",
    "# load all the libraries you need (pandas, numpy matplotlib etc and ALL the scikit-learn stuff for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf83c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore our data\n",
    "# Do the usual .head(), .info(), .describe(), missing values etc\n",
    "# HOWEVER, THIS IS THE PLACE WHERE WE BECOME SUBJECT MATTER EXPERTS OF EACH COLUMN IN OUR DATA\n",
    "# Example: Try to see what is the ratio of male to women having heart disease?\n",
    "    # BASED ON OUR DATA (NOT REAL WORLD): Who is more likely to get heart disease? M or F? \n",
    "    # Is our data biased?   \n",
    "# Essentially, explore each column and it's relationship with the target column and every other column\n",
    "# Get a mental map of what a prediction will look like BASED ON THE CURRENT DATA, and out goal should be to improve it\n",
    "\n",
    "# This is what EDA is all about.\n",
    "# Also keep this as a good resource: https://github.com/nevaan9/Hands-On-Data-Analysis-with-Pandas-2nd-edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f3f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model and run data into those models\n",
    "# Try different models (datacamp repo has some examples how to do this)\n",
    "\n",
    "# Then do some hyper param tuning:\n",
    "# Search for \"How to tune knnn classifier model\" if you wanna tune knn\n",
    "\n",
    "# Daniel gives a nice overview of what each row in the CLASSIFICATION_REPORT table returns - Watch the video in Evaluating A Model 2 and write them down\n",
    "# ALSO READ READ READ SCIKIT-LEARN DOCS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf7160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance!\n",
    "\n",
    "# First google: \"How to find feature importance for <model type>\"\n",
    "# Read and try to understand the different strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d05e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentation\n",
    "\n",
    "# If you haven't hit your evaluation metric yet... ask yourself...\n",
    "\n",
    "# Could you collect more data?\n",
    "# Could you try a better model? Like CatBoost or XGBoost?\n",
    "# Could you improve the current models? (beyond what we've done so far)\n",
    "# If your model is good enough (you have hit your evaluation metric) how would you export it and share it with others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af9880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
